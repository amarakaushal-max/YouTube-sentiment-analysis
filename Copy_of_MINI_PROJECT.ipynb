{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GU2x6nCUDF5T",
        "outputId": "e00b5462-de48-45e1-d1b4-df6b85717b36"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting streamlit\n",
            "  Downloading streamlit-1.54.0-py3-none-any.whl.metadata (9.8 kB)\n",
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.5.0-py3-none-any.whl.metadata (8.1 kB)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.12/dist-packages (2.190.0)\n",
            "Collecting emoji\n",
            "  Downloading emoji-2.15.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting vaderSentiment\n",
            "  Downloading vaderSentiment-3.3.2-py2.py3-none-any.whl.metadata (572 bytes)\n",
            "Requirement already satisfied: altair!=5.4.0,!=5.4.1,<7,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (1.9.0)\n",
            "Collecting cachetools<7,>=5.5 (from streamlit)\n",
            "  Downloading cachetools-6.2.6-py3-none-any.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (8.3.1)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.12/dist-packages (from streamlit) (3.1.46)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (26.0)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<13,>=7.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (11.3.0)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.29.6)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.32.4)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (9.1.4)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.12/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.5.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (4.15.0)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.12/dist-packages (from pyngrok) (6.0.3)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client) (0.31.2)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client) (2.47.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client) (0.3.0)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client) (2.29.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client) (4.2.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (4.26.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (2.16.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (1.72.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (1.27.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client) (4.9.1)\n",
            "Requirement already satisfied: pyparsing<4,>=3.1 in /usr/local/lib/python3.12/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client) (3.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (2026.1.4)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (3.0.3)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (25.4.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.25.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (0.30.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client) (0.6.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
            "Downloading streamlit-1.54.0-py3-none-any.whl (9.1 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m9.1/9.1 MB\u001b[0m \u001b[31m41.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyngrok-7.5.0-py3-none-any.whl (24 kB)\n",
            "Downloading emoji-2.15.0-py3-none-any.whl (608 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m608.4/608.4 kB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading vaderSentiment-3.3.2-py2.py3-none-any.whl (125 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m126.0/126.0 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cachetools-6.2.6-py3-none-any.whl (11 kB)\n",
            "Downloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m79.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyngrok, emoji, cachetools, vaderSentiment, pydeck, streamlit\n",
            "  Attempting uninstall: cachetools\n",
            "    Found existing installation: cachetools 7.0.1\n",
            "    Uninstalling cachetools-7.0.1:\n",
            "      Successfully uninstalled cachetools-7.0.1\n",
            "Successfully installed cachetools-6.2.6 emoji-2.15.0 pydeck-0.9.1 pyngrok-7.5.0 streamlit-1.54.0 vaderSentiment-3.3.2\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "if 'google.colab' in sys.modules:\n",
        "  !pip install streamlit pyngrok google-api-python-client emoji vaderSentiment\n",
        "\n",
        "# Import necessary libraries\n",
        "import streamlit as st\n",
        "from pyngrok import ngrok\n",
        "from IPython.display import display, Markdown"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mIIR2nX8DVza",
        "outputId": "0817af86-bd35-46ad-8d67-9cf153b471db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from wordcloud import WordCloud\n",
        "# from pyngrok import ngrok # ngrok is used to tunnel, not directly in app.py\n",
        "\n",
        "# New imports for YouTube API and sentiment analysis\n",
        "from googleapiclient.discovery import build\n",
        "import re\n",
        "import emoji\n",
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
        "\n",
        "#  Page Config\n",
        "st.set_page_config(page_title=\"YouTube Sentiment Analyzer\", page_icon=\"üéØ\", layout=\"wide\")\n",
        "\n",
        "#  Step 2: Header Section\n",
        "st.title(\" YouTube Sentiment Analyzer\")\n",
        "st.subheader(\"Analyze what viewers really feel about your video\")\n",
        "\n",
        "# Input field for YouTube URL\n",
        "youtube_url = st.text_input(\"Paste YouTube Video URL here \")\n",
        "analyze_btn = st.button(\"Analyze Comments\")\n",
        "\n",
        "# --- Function to fetch and analyze comments ---\n",
        "def fetch_and_analyze_comments(youtube_url):\n",
        "    API_KEY = 'AIzaSyBmtsVe0jxC7jzirb7z_SPQctTIwkE5aGc' # Using the same key from mZD7kbb_rZUu\n",
        "    youtube = build('youtube', 'v3', developerKey=API_KEY)\n",
        "\n",
        "    match = re.search(r'(?<=v=)[a-zA-Z0-9_-]+', youtube_url)\n",
        "    x = match.group(0) if match else None\n",
        "\n",
        "    if not x:\n",
        "        st.error(\"Error: Invalid YouTube URL. Could not extract video ID.\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    # Getting the channelId of the video uploader\n",
        "    video_response = youtube.videos().list(\n",
        "        part='snippet',\n",
        "        id=x\n",
        "    ).execute()\n",
        "\n",
        "    uploader_channel_id = None\n",
        "    if video_response and 'items' in video_response and len(video_response['items']) > 0:\n",
        "        video_snippet = video_response['items'][0]['snippet']\n",
        "        uploader_channel_id = video_snippet['channelId']\n",
        "    else:\n",
        "        st.error(f\"Error: No video data found for ID '{x}'. It might be invalid, private, or deleted.\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    comments = []\n",
        "    nextPageToken = None\n",
        "    progress_bar = st.progress(0)\n",
        "    status_text = st.empty()\n",
        "    total_comments_to_fetch = 600 # Max comments to fetch\n",
        "\n",
        "    status_text.text(\"Fetching Comments...\")\n",
        "    fetched_count = 0\n",
        "    while fetched_count < total_comments_to_fetch:\n",
        "        request = youtube.commentThreads().list(\n",
        "            part='snippet',\n",
        "            videoId=x,\n",
        "            maxResults=100,\n",
        "            pageToken=nextPageToken\n",
        "        )\n",
        "        response = request.execute()\n",
        "        for item in response['items']:\n",
        "            comment = item['snippet']['topLevelComment']['snippet']\n",
        "            if comment['authorChannelId']['value'] != uploader_channel_id:\n",
        "                comments.append(comment['textDisplay'])\n",
        "                fetched_count += 1\n",
        "                if fetched_count >= total_comments_to_fetch:\n",
        "                    break\n",
        "        nextPageToken = response.get('nextPageToken')\n",
        "\n",
        "        progress_bar.progress(min(fetched_count, total_comments_to_fetch) / total_comments_to_fetch)\n",
        "        status_text.text(f\"Fetched {fetched_count} comments...\")\n",
        "\n",
        "        if not nextPageToken or fetched_count >= total_comments_to_fetch:\n",
        "            break\n",
        "    status_text.text(f\"Finished fetching {fetched_count} comments.\")\n",
        "\n",
        "    # Filter relevant comments\n",
        "    hyperlink_pattern = re.compile(\n",
        "        r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')\n",
        "    threshold_ratio = 0.65\n",
        "    relevant_comments = []\n",
        "\n",
        "    for comment_text in comments:\n",
        "        comment_text = comment_text.lower().strip()\n",
        "        emojis_count = emoji.emoji_count(comment_text)\n",
        "        text_characters = len(re.sub(r'\\s', '', comment_text))\n",
        "\n",
        "        if (any(char.isalnum() for char in comment_text)) and not hyperlink_pattern.search(comment_text):\n",
        "            if emojis_count == 0 or (text_characters / (text_characters + emojis_count)) > threshold_ratio:\n",
        "                relevant_comments.append(comment_text)\n",
        "\n",
        "    # Sentiment Analysis\n",
        "    analyzer = SentimentIntensityAnalyzer()\n",
        "    sentiment_data = []\n",
        "\n",
        "    status_text.text(\"Analyzing Comments...\")\n",
        "    for i, comment_text in enumerate(relevant_comments):\n",
        "        vs = analyzer.polarity_scores(comment_text)\n",
        "        compound_score = vs['compound']\n",
        "\n",
        "        sentiment_label = \"\"\n",
        "        if compound_score >= 0.05:\n",
        "            sentiment_label = \"positive\"\n",
        "        elif compound_score <= -0.05:\n",
        "            sentiment_label = \"negative\"\n",
        "        else:\n",
        "            sentiment_label = \"neutral\"\n",
        "        sentiment_data.append({'comment': comment_text, 'sentiment': sentiment_label, 'compound_score': compound_score})\n",
        "        progress_bar.progress((i + 1) / len(relevant_comments))\n",
        "    status_text.text(\"Finished analyzing comments.\")\n",
        "\n",
        "\n",
        "    return pd.DataFrame(sentiment_data)\n",
        "\n",
        "\n",
        "if analyze_btn and youtube_url:\n",
        "    with st.spinner('Analyzing YouTube comments...'):\n",
        "        df = fetch_and_analyze_comments(youtube_url)\n",
        "\n",
        "    if not df.empty:\n",
        "        # Step 3: Overview Section\n",
        "        total_comments = len(df)\n",
        "        positive_count = (df['sentiment'] == 'positive').sum()\n",
        "        neutral_count = (df['sentiment'] == 'neutral').sum()\n",
        "        negative_count = (df['sentiment'] == 'negative').sum()\n",
        "\n",
        "        st.markdown(\" Overview Summary\")\n",
        "        col1, col2, col3 = st.columns(3)\n",
        "        col1.metric(\"Total Comments\", total_comments)\n",
        "        col2.metric(\"Positive\", positive_count)\n",
        "        col3.metric(\"Negative\", negative_count)\n",
        "\n",
        "        #  Generate a basic summary\n",
        "        overall_sentiment = \"Mixed\"\n",
        "        if positive_count > negative_count and positive_count > neutral_count:\n",
        "            overall_sentiment = \"Mostly Positive\"\n",
        "        elif negative_count > positive_count and negative_count > neutral_count:\n",
        "            overall_sentiment = \"Mostly Negative\"\n",
        "        elif neutral_count > positive_count and neutral_count > negative_count:\n",
        "            overall_sentiment = \"Mostly Neutral\"\n",
        "\n",
        "\n",
        "        summary_text = f\"Overall viewers felt **{overall_sentiment}** about this video. \"\n",
        "\n",
        "        st.write(summary_text)\n",
        "\n",
        "        #  Step 4: Sentiment Distribution Charts\n",
        "        st.markdown(\" Sentiment Distribution\")\n",
        "        sentiment_counts = df['sentiment'].value_counts()\n",
        "\n",
        "        # Define custom colors for the pie chart\n",
        "        colors = {'positive': 'green', 'negative': 'red', 'neutral': 'gray'}\n",
        "        # Ensure the order of colors matches the order of sentiments in sentiment_counts.index\n",
        "        ordered_colors = [colors[s] for s in sentiment_counts.index]\n",
        "\n",
        "        fig, ax = plt.subplots()\n",
        "        wedges, texts, autotexts = ax.pie(sentiment_counts, labels=sentiment_counts.index, autopct='%1.1f%%', startangle=90, colors=ordered_colors, textprops={'color': 'white'})\n",
        "\n",
        "        # Make the percentage labels more visible\n",
        "        for autotext in autotexts:\n",
        "            autotext.set_color('white')\n",
        "            autotext.set_fontsize(12)\n",
        "        for text in texts:\n",
        "            text.set_fontsize(10)\n",
        "\n",
        "        ax.axis('equal') # Equal aspect ratio ensures that pie is drawn as a circle.\n",
        "        st.pyplot(fig)\n",
        "\n",
        "        #  Step 5: Word Cloud / Keywords\n",
        "        st.markdown(\"# Common Keywords\")\n",
        "        # Ensure there are comments to generate a word cloud\n",
        "        if not df['comment'].empty:\n",
        "            text = \" \".join(df['comment'])\n",
        "            if text: # Check if text is not empty after joining\n",
        "                wordcloud = WordCloud(width=800, height=400, background_color='white').generate(text)\n",
        "                fig_wc, ax_wc = plt.subplots(figsize=(10,5)) # Use separate fig, ax for wordcloud\n",
        "                ax_wc.imshow(wordcloud, interpolation='bilinear')\n",
        "                ax_wc.axis(\"off\")\n",
        "                st.pyplot(fig_wc)\n",
        "            else:\n",
        "                st.info(\"No relevant comments to generate a word cloud.\")\n",
        "        else:\n",
        "            st.info(\"No comments available to generate a word cloud.\")\n",
        "\n",
        "\n",
        "        #  Step 6: Sample Comments\n",
        "        st.markdown(\" Sample Comments\")\n",
        "        for i, row in df.head(10).iterrows(): # Display top 10 sample comments\n",
        "            sentiment_color = {\"positive\":\"üü¢\", \"negative\":\"üî¥\", \"neutral\":\"üü°\"}.get(row['sentiment'], \"‚ö™\") # Default to white circle if sentiment not found\n",
        "            st.write(f\"{sentiment_color} {row['comment']}\")\n",
        "\n",
        "        #  Download Section\n",
        "        st.download_button(\n",
        "            label=\"üíæ Download Results as CSV\",\n",
        "            data=df[['comment', 'sentiment', 'compound_score']].to_csv(index=False).encode('utf-8'),\n",
        "            file_name='sentiment_results.csv',\n",
        "            mime='text/csv'\n",
        "        )\n",
        "    else:\n",
        "        st.warning(\"No comments were fetched or analyzed for the provided URL.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "hVlkXFUGPxLe",
        "outputId": "06f54498-f0fb-4a11-86a6-e69c22d136fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": []
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Your Streamlit app is live at: NgrokTunnel: \"https://egal-overstoutly-jayla.ngrok-free.dev\" -> \"http://localhost:8501\""
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://35.185.168.191:8501\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Stopping...\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from pyngrok import ngrok\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "# Start ngrok tunnel and launch Streamlit\n",
        "\n",
        "# Terminate any existing ngrok tunnels\n",
        "ngrok.kill()\n",
        "\n",
        "# Get ngrok authentication token (replace 'YOUR_NGROK_AUTH_TOKEN' with your actual token)\n",
        "# You can get an auth token from https://ngrok.com/signup\n",
        "# It's recommended to store your ngrok token in Colab secrets.\n",
        "# Click the 'üîë' icon on the left panel, add a new secret named 'NGROK_AUTH_TOKEN' and paste your token.\n",
        "\n",
        "NGROK_AUTH_TOKEN = os.environ.get(\"NGROK_AUTH_TOKEN\", \"36KSz5D47d8OFL50NyJAGErrlY7_6Ssx7WvAgSNd2GhtbdaKK\")\n",
        "\n",
        "if NGROK_AUTH_TOKEN ==\"YOUR_NGROK_AUTH_TOKEN\":\n",
        "    display(Markdown(\"**Please set your ngrok auth token in Colab secrets or replace 'YOUR_NGROK_AUTH_TOKEN' in the code.**\"))\n",
        "else:\n",
        "    ngrok.set_auth_token(NGROK_AUTH_TOKEN)\n",
        "\n",
        "    # Start a ngrok tunnel for Streamlit (default port is 8501)\n",
        "    public_url = ngrok.connect(8501)\n",
        "    display(Markdown(f\"Your Streamlit app is live at: {public_url}\"))\n",
        "\n",
        "    # Run the Streamlit app in the background using 'python -m streamlit'\n",
        "    !python -m streamlit run app.py &"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}